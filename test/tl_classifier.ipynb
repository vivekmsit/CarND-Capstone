{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from styx_msgs.msg import TrafficLight\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import zipfile\n",
    "import tarfile\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#import rospy\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import six.moves.urllib as urllib\n",
    "\n",
    "class TLClassifier(object):\n",
    "    def __init__(self, download=False):\n",
    "        self.MODEL_NAME = None\n",
    "        if \"1.3.0\" in tf.__version__:\n",
    "            #self.MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "            self.MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "        else:\n",
    "            #self.MODEL_NAME = 'ssdlite_mobilenet_v2_coco_2018_05_09'\n",
    "            self.MODEL_NAME = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
    "        print(\"using ssd model: \" + self.MODEL_NAME)\n",
    "\n",
    "        # Download coco model\n",
    "        if download is True:\n",
    "            self.download_coco_model()\n",
    "\n",
    "        # Path to frozen detection graph.\n",
    "        PATH_TO_CKPT = self.MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "        self.model = None\n",
    "        self.width = 0\n",
    "        self.height = 0\n",
    "        self.channels = 3\n",
    "        self.gamma = 0.6\n",
    "        self.image_count = 0\n",
    "        self.correct_gamma = True\n",
    "\n",
    "        # Load a frozen model into memory\n",
    "        self.detection_graph = tf.Graph()\n",
    "        with self.detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "            self.sess = tf.Session(graph=self.detection_graph)\n",
    "            # Input and output Tensors for detection_graph\n",
    "            self.image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            self.detection_boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            self.detection_scores = self.detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            self.detection_classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            self.num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    def download_coco_model(self):\n",
    "        \"\"\"Downloads coco model\"\"\"\n",
    "        MODEL_FILE = self.MODEL_NAME + '.tar.gz'\n",
    "        DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "        if os.path.exists(self.MODEL_NAME):\n",
    "            print(\"model already downloaded\")\n",
    "            return\n",
    "        else:\n",
    "            URL_PATH = DOWNLOAD_BASE + MODEL_FILE\n",
    "            print(\"downloading model from \" + URL_PATH)\n",
    "            response = urlopen(URL_PATH)\n",
    "            f = open(MODEL_FILE, 'wb')\n",
    "            f.write(response.read())\n",
    "            f.close()\n",
    "            print(\"downloaded model successfully\")\n",
    "        print(\"extracting model\")\n",
    "        tar_file = tarfile.open(MODEL_FILE)\n",
    "        for file in tar_file.getmembers():\n",
    "            file_name = os.path.basename(file.name)\n",
    "            if 'frozen_inference_graph.pb' in file_name:\n",
    "                tar_file.extract(file, os.getcwd())\n",
    "                print(\"extracted model successfully\")\n",
    "        tar_file.close()\n",
    "        os.remove(MODEL_FILE) # remove .tar.gz file\n",
    "\n",
    "    def get_classification(self, image):\n",
    "        \"\"\"Determines the color of the traffic light in the image\n",
    "        Args:\n",
    "            image (cv::Mat): image containing the traffic light\n",
    "        Returns:\n",
    "            int: ID of traffic light color (specified in styx_msgs/TrafficLight)\n",
    "        \"\"\"\n",
    "        tl_color = None\n",
    "        if self.correct_gamma:\n",
    "            if self.gamma == 1.0:\n",
    "                self.gamma = 0.6\n",
    "            elif self.gamma == 0.6:\n",
    "                self.gamma = 1.0\n",
    "        image = self.adjust_gamma(image, self.gamma)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_np = np.asarray(image, dtype=\"uint8\")\n",
    "        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "        detected = False\n",
    "\n",
    "        with self.detection_graph.as_default():\n",
    "            (boxes, scores, classes, num) = self.sess.run(\n",
    "                [self.detection_boxes, self.detection_scores, self.detection_classes, self.num_detections],\n",
    "                feed_dict={self.image_tensor: image_np_expanded})\n",
    "        boxes = np.squeeze(boxes)\n",
    "        classes = np.squeeze(classes).astype(np.int32)\n",
    "        scores = np.squeeze(scores)\n",
    "        best_scores = []\n",
    "\n",
    "        for idx, classID in enumerate(classes):\n",
    "            if self.MODEL_NAME == 'ssdlite_mobilenet_v2_coco_2018_05_09':\n",
    "                if classID == 10: # 10 is traffic light\n",
    "                    if scores[idx] > 0.10: #confidence level\n",
    "                        best_scores.append([scores[idx], idx, classID])\n",
    "                        detected = True\n",
    "            else: # we tuned the model to classify only traffic lights\n",
    "                if scores[idx] > 0.10:  # confidence level\n",
    "                    best_scores.append([scores[idx], idx, classID])\n",
    "                    detected = True\n",
    "\n",
    "        tl_index = -1\n",
    "        if detected:\n",
    "            best_scores.sort(key=lambda tup: tup[0], reverse=True)\n",
    "\n",
    "            best_score = best_scores[0]\n",
    "            #print(\"number of TL found %d, best score: %f, color: %f\", len(best_scores), best_score[0], best_score[2])\n",
    "            nbox = boxes[best_score[1]]\n",
    "\n",
    "            height = image.shape[0]\n",
    "            width = image.shape[1]\n",
    "\n",
    "            box = np.array([nbox[0]*height, nbox[1]*width, nbox[2]*height, nbox[3]*width]).astype(int)\n",
    "            box_height = box[2] - box[0]\n",
    "            box_width = box[3] - box[1]\n",
    "            ratio = float(box_height)/float(box_width)\n",
    "            #print(\"ratio: %f\", ratio)\n",
    "            if ratio >= 2.0 and ratio < 3.0: #started from 2.4\n",
    "                tl_cropped = image[box[0]:box[2], box[1]:box[3]]\n",
    "                tl_color, tl_index = self.get_color(tl_cropped)\n",
    "                #print(\"traffic light color is: \" + tl_color)\n",
    "                #augment image with detected TLs\n",
    "                cv2.rectangle(image, (box[1], box[0]), (box[3], box[2]), (0, 255, 0), 2)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_color = (255, 255, 255)\n",
    "                cv2.putText(image, tl_color, (box[1], box[0]), font, 2.0, font_color, lineType=cv2.LINE_AA)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # convert image back to BGR\n",
    "        return image, tl_index, tl_color\n",
    "\n",
    "    def get_color(self, image_rgb):\n",
    "        image_lab = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2LAB)\n",
    "        l = image_lab.copy()\n",
    "        # set a and b channels to 0\n",
    "        l[:, :, 1] = 0\n",
    "        l[:, :, 2] = 0\n",
    "\n",
    "        std_l = self.standardize_input(l)\n",
    "\n",
    "        red_slice, yellow_slice, green_slice = self.slice_image(std_l)\n",
    "\n",
    "        y, x, c = red_slice.shape\n",
    "        px_sums = []\n",
    "        color = ['RED', 'YELLOW', 'GREEN', 'UNKNOWN']\n",
    "        px_sums.append(np.sum(red_slice[0:y, 0:x, 0]))\n",
    "        px_sums.append(np.sum(yellow_slice[0:y, 0:x, 0]))\n",
    "        px_sums.append(np.sum(green_slice[0:y, 0:x, 0]))\n",
    "\n",
    "        max_value = max(px_sums)\n",
    "        max_index = px_sums.index(max_value)\n",
    "\n",
    "        return color[max_index], max_index\n",
    "\n",
    "    def crop(self, image):\n",
    "        row = 2\n",
    "        col = 6\n",
    "        cropped_img = image.copy()\n",
    "        cropped_img = cropped_img[row:-row, col:-col, :]\n",
    "        return cropped_img\n",
    "\n",
    "    def standardize_input(self, image):\n",
    "        standard_img = np.copy(image)\n",
    "        standard_img = cv2.resize(standard_img, (32, 32))\n",
    "        standard_img = self.crop(standard_img)\n",
    "        return standard_img\n",
    "\n",
    "    def slice_image(self, image):\n",
    "        img = image.copy()\n",
    "        shape = img.shape\n",
    "        slice_height = int(shape[0] / 3)\n",
    "        upper = img[0:slice_height, :, :]\n",
    "        middle = img[slice_height:2 * slice_height, :, :]\n",
    "        lower = img[2 * slice_height:3 * slice_height, :, :]\n",
    "        return upper, middle, lower\n",
    "\n",
    "    def enhance_image(self, image_bgr, gridsize=2): # Contrast Limited Adaptive Histogram Equalization\n",
    "        image_lab = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2LAB)\n",
    "        lab_planes = cv2.split(image_lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(gridsize, gridsize))\n",
    "        lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "        image_lab = cv2.merge(lab_planes)\n",
    "        image_bgr = cv2.cvtColor(image_lab, cv2.COLOR_LAB2BGR)\n",
    "        image_bgr = cv2.GaussianBlur(image_bgr, (3, 3), 0)\n",
    "        return image_bgr\n",
    "\n",
    "    def adjust_gamma(self, bgr, gamma=1.0):\n",
    "        # build a lookup table mapping the pixel values [0, 255] to\n",
    "        # their adjusted gamma values\n",
    "        invGamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                          for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        # apply gamma correction using the lookup table\n",
    "        return cv2.LUT(bgr, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "using ssd model: ssd_mobilenet_v2_coco_2018_03_29\n",
      "model already downloaded\n",
      "Processing images and creating video\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(\"reading input image\")\n",
    "img = cv2.imread('rosbag_data/images/frame0150.jpg', cv2.IMREAD_COLOR)\n",
    "print(\"classifying image\")\n",
    "tl_image_rgb, color_index = light_classifier.get_classification(img)\n",
    "print(\"End\")\n",
    "\"\"\"\n",
    "\n",
    "from os.path import isfile, join\n",
    "\n",
    "print(\"Start\")\n",
    "light_classifier = TLClassifier(True)\n",
    "\n",
    "pathIn= './rosbag_data/images/'\n",
    "pathOut = './rosbag_data/video.avi'\n",
    "fps = 5.0\n",
    "\n",
    "frame_array = []\n",
    "files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    "\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: int(x[5:-4]))\n",
    "print(\"Processing images and creating video\")\n",
    "for i in range(len(files)):\n",
    "    filename=pathIn + files[i]\n",
    "    #reading each file\n",
    "    img = cv2.imread(filename)\n",
    "    img, color_index, tl_color = light_classifier.get_classification(img)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    #inserting the frames into an image array\n",
    "    frame_array.append(img)\n",
    "out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    " \n",
    "for i in range(len(frame_array)):\n",
    "    # writing to a image array\n",
    "    out.write(frame_array[i])\n",
    "out.release()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
