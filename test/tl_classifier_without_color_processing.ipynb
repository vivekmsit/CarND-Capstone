{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from styx_msgs.msg import TrafficLight\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import zipfile\n",
    "import tarfile\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not os.path.exists('object_detection'):\n",
    "    print(\"Copy object_detection directory from $(Tensorflow)\\models\\research directory\")\n",
    "    exit()\n",
    "\n",
    "sys.path.append('object_detection')\n",
    "sys.path.append('object_detection/utils')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "#from utils import label_map_util\n",
    "#from utils import visualization_utils as vis_util\n",
    "\n",
    "import label_map_util\n",
    "import visualization_utils as vis_util\n",
    "\n",
    "#import rospy\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import six.moves.urllib as urllib\n",
    "\n",
    "class TLClassifier(object):\n",
    "    def __init__(self, download=False):\n",
    "        self.MODEL_NAME = None\n",
    "        self.MODEL_NAME = self.setup_ssd_model()\n",
    "        print(\"using ssd model: \" + self.MODEL_NAME)\n",
    "        MODEL_PATH = 'models/' + self.MODEL_NAME\n",
    "        # Path to frozen detection graph.\n",
    "        PATH_TO_CKPT = MODEL_PATH + '/frozen_inference_graph.pb'\n",
    "\n",
    "        self.model = None\n",
    "        self.width = 0\n",
    "        self.height = 0\n",
    "        self.channels = 3\n",
    "        self.gamma = 0.6\n",
    "        self.image_count = 0\n",
    "        self.correct_gamma = True\n",
    "\n",
    "        # Load a frozen model into memory\n",
    "        self.detection_graph = tf.Graph()\n",
    "        with self.detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "            self.sess = tf.Session(graph=self.detection_graph)\n",
    "            # Input and output Tensors for detection_graph\n",
    "            self.image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            self.detection_boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            self.detection_scores = self.detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            self.detection_classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            self.num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        self.category_index = self.get_category_index()\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "\n",
    "    def setup_ssd_model(self):\n",
    "        MODEL_NAME = None\n",
    "        MODEL_NAME = 'alex-lechner_udacity_trained_model'\n",
    "        #MODEL_NAME = 'real_mobilenets_ssd_38k_epochs'\n",
    "        #MODEL_NAME = 'sim_mobilenets_ssd_30k_epochs'\n",
    "        return MODEL_NAME\n",
    "\n",
    "        if \"1.3.0\" in tf.__version__:\n",
    "            #MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "            MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "        else:\n",
    "            #MODEL_NAME = 'ssdlite_mobilenet_v2_coco_2018_05_09'\n",
    "            MODEL_NAME = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
    "        \"\"\"Downloads coco model\"\"\"\n",
    "        MODEL_FILE = 'models/' + MODEL_NAME + '.tar.gz'\n",
    "        DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "        if os.path.exists('models/' + MODEL_NAME):\n",
    "            print(\"model already downloaded\")\n",
    "            return\n",
    "        else:\n",
    "            URL_PATH = DOWNLOAD_BASE + MODEL_NAME + '.tar.gz'\n",
    "            print(\"downloading model from \" + URL_PATH)\n",
    "            response = urlopen(URL_PATH)\n",
    "            f = open(MODEL_FILE, 'wb')\n",
    "            f.write(response.read())\n",
    "            f.close()\n",
    "            print(\"downloaded model successfully\")\n",
    "        print(\"extracting model\")\n",
    "        tar_file = tarfile.open(MODEL_FILE)\n",
    "        for file in tar_file.getmembers():\n",
    "            file_name = os.path.basename(file.name)\n",
    "            if 'frozen_inference_graph.pb' in file_name:\n",
    "                tar_file.extract(file, os.getcwd()+ '/models')\n",
    "                #tar_file.extractall(os.getcwd()+ '/models')\n",
    "                print(\"extracted model successfully\")\n",
    "        tar_file.close()\n",
    "        os.remove(MODEL_FILE) # remove .tar.gz file\n",
    "        return MODEL_NAME\n",
    "\n",
    "    def get_category_index(self):\n",
    "        PATH_TO_LABELS = r'models\\alex-lechner_udacity_trained_model\\data\\udacity_label_map.pbtxt'\n",
    "        NUM_CLASSES = 13\n",
    "        label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "        categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "        category_index = label_map_util.create_category_index(categories)\n",
    "        #print(category_index)\n",
    "        return category_index\n",
    "\n",
    "    def load_image_into_numpy_array(self, image):\n",
    "        (im_width, im_height) = image.size\n",
    "        return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "    def get_classification(self, img_path):\n",
    "        tl_index = None\n",
    "        tl_color = None\n",
    "        image = Image.open(img_path)\n",
    "        image_np = self.load_image_into_numpy_array(image)\n",
    "        image_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "        (boxes, scores, classes, num) = self.sess.run(\n",
    "            [self.detection_boxes, self.detection_scores, self.detection_classes, self.num_detections],\n",
    "            feed_dict={self.image_tensor: image_expanded})\n",
    "\n",
    "        #print('SCORES')\n",
    "        #print(scores[0])\n",
    "        #print('CLASSES')\n",
    "        #print(classes[0])\n",
    "\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np, \n",
    "            np.squeeze(boxes),\n",
    "            np.squeeze(classes).astype(np.int32),\n",
    "            np.squeeze(scores),\n",
    "            self.category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            line_thickness=8)\n",
    "        #plt.figure(figsize=(12,8))\n",
    "        #plt.imshow(image_np)\n",
    "        #plt.show()\n",
    "        return image_np, tl_index, tl_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "using ssd model: alex-lechner_udacity_trained_model\n",
      "Processing images and creating video\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from os.path import isfile, join\n",
    "\n",
    "print(\"Start\")\n",
    "light_classifier = TLClassifier(True)\n",
    "model_name = light_classifier.get_model_name()\n",
    "\n",
    "#pathIn= './input/rosbag_data_1/images/'\n",
    "pathIn= './input/rosbag_data_2/images/'\n",
    "pathOut = './models/' + model_name + '/video.avi'\n",
    "fps = 5.0\n",
    "\n",
    "frame_array = []\n",
    "files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    "\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: int(x[5:-4]))\n",
    "print(\"Processing images and creating video\")\n",
    "for i in range(len(files)):\n",
    "    filepath=pathIn + files[i]\n",
    "    #reading each file\n",
    "    #img = cv2.imread(filepath)\n",
    "    img, color_index, tl_color = light_classifier.get_classification(filepath)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    #inserting the frames into an image array\n",
    "    frame_array.append(img)\n",
    "    #break\n",
    "out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "\n",
    "for i in range(len(frame_array)):\n",
    "    # writing to a image array\n",
    "    out.write(frame_array[i])\n",
    "out.release()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
